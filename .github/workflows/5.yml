name: T5 (Shards 20–24)

on:
  workflow_dispatch:   # Manual run
  schedule:
    # 5:34 PM IST = 12:04 UTC
    # Runs ONLY Monday–Friday
    - cron: '20 12 * * 1-5'

jobs:
  scrape:
    runs-on: ubuntu-22.04

    strategy:
      fail-fast: false
      max-parallel: 2
      matrix:
        shard: [20,21,22,23,24]

    env:
      SHARD_STEP: 20

    steps:
      - uses: actions/checkout@v4

      - uses: actions/setup-python@v5
        with:
          python-version: '3.10'

      - name: Install dependencies
        run: pip install selenium beautifulsoup4 gspread webdriver-manager

      - name: Write credentials
        run: |
          echo '${{ secrets.GSPREAD_CREDENTIALS }}' > credentials.json
          echo '${{ secrets.TRADINGVIEW_COOKIES }}' > cookies.json

      - name: Init checkpoint
        run: |
          FILE="checkpoint_group5_${{ matrix.shard }}.txt"
          [ ! -f "$FILE" ] && echo "1" > "$FILE"

      - name: Run scraper
        env:
          SHARD_INDEX: ${{ matrix.shard }}
          CHECKPOINT_FILE: checkpoint_group5_${{ matrix.shard }}.txt
        run: python run_scraper.py
